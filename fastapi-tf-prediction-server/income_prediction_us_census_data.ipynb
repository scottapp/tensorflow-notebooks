{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c39ca524-f2fc-4eff-b41d-ae3060b12644",
   "metadata": {},
   "source": [
    "# Income Bracket Prediction Based On US Census Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52c56561-bbd1-454a-a880-14e71479dedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.10 | packaged by conda-forge | (main, Feb  1 2022, 21:24:11) \n",
      "[GCC 9.4.0]\n",
      "2.6.2\n",
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from six.moves import urllib\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "print(__import__('sys').version)\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee8922b2-84e8-4b38-b554-ee643bfb028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(tempfile.gettempdir(), 'census_data')\n",
    "\n",
    "# Download options.\n",
    "DATA_URL = 'https://storage.googleapis.com/cloud-samples-data/ai-platform/census/data'\n",
    "TRAINING_FILE = 'adult.data.csv'\n",
    "EVAL_FILE = 'adult.test.csv'\n",
    "TRAINING_URL = '%s/%s' % (DATA_URL, TRAINING_FILE)\n",
    "EVAL_URL = '%s/%s' % (DATA_URL, EVAL_FILE)\n",
    "\n",
    "### For interpreting data ###\n",
    "\n",
    "# These are the features in the dataset.\n",
    "# Dataset information: https://archive.ics.uci.edu/ml/datasets/census+income\n",
    "_CSV_COLUMNS = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
    "    'marital_status', 'occupation', 'relationship', 'race', 'gender',\n",
    "    'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "    'income_bracket'\n",
    "]\n",
    "\n",
    "_CATEGORICAL_TYPES = {\n",
    "  'workclass': pd.api.types.CategoricalDtype(categories=[\n",
    "    'Federal-gov', 'Local-gov', 'Never-worked', 'Private', 'Self-emp-inc',\n",
    "    'Self-emp-not-inc', 'State-gov', 'Without-pay'\n",
    "  ]),\n",
    "  'marital_status': pd.api.types.CategoricalDtype(categories=[\n",
    "    'Divorced', 'Married-AF-spouse', 'Married-civ-spouse',\n",
    "    'Married-spouse-absent', 'Never-married', 'Separated', 'Widowed'\n",
    "  ]),\n",
    "  'occupation': pd.api.types.CategoricalDtype([\n",
    "    'Adm-clerical', 'Armed-Forces', 'Craft-repair', 'Exec-managerial',\n",
    "    'Farming-fishing', 'Handlers-cleaners', 'Machine-op-inspct',\n",
    "    'Other-service', 'Priv-house-serv', 'Prof-specialty', 'Protective-serv',\n",
    "    'Sales', 'Tech-support', 'Transport-moving'\n",
    "  ]),\n",
    "  'relationship': pd.api.types.CategoricalDtype(categories=[\n",
    "    'Husband', 'Not-in-family', 'Other-relative', 'Own-child', 'Unmarried',\n",
    "    'Wife'\n",
    "  ]),\n",
    "  'race': pd.api.types.CategoricalDtype(categories=[\n",
    "    'Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other', 'White'\n",
    "  ]),\n",
    "  'native_country': pd.api.types.CategoricalDtype(categories=[\n",
    "    'Cambodia', 'Canada', 'China', 'Columbia', 'Cuba', 'Dominican-Republic',\n",
    "    'Ecuador', 'El-Salvador', 'England', 'France', 'Germany', 'Greece',\n",
    "    'Guatemala', 'Haiti', 'Holand-Netherlands', 'Honduras', 'Hong', 'Hungary',\n",
    "    'India', 'Iran', 'Ireland', 'Italy', 'Jamaica', 'Japan', 'Laos', 'Mexico',\n",
    "    'Nicaragua', 'Outlying-US(Guam-USVI-etc)', 'Peru', 'Philippines', 'Poland',\n",
    "    'Portugal', 'Puerto-Rico', 'Scotland', 'South', 'Taiwan', 'Thailand',\n",
    "    'Trinadad&Tobago', 'United-States', 'Vietnam', 'Yugoslavia'\n",
    "  ]),\n",
    "  'income_bracket': pd.api.types.CategoricalDtype(categories=[\n",
    "    '<=50K', '>50K'\n",
    "  ])\n",
    "}\n",
    "\n",
    "# This is the label (target) we want to predict.\n",
    "_LABEL_COLUMN = 'income_bracket'\n",
    "\n",
    "### Hyperparameters for training ###\n",
    "\n",
    "# This the training batch size\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# This is the number of epochs (passes over the full training data)\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "# Define learning rate.\n",
    "LEARNING_RATE = .01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14ad3cc0-ab8f-46d0-b913-b74c67ee7a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _download_and_clean_file(filename, url):\n",
    "  \"\"\"Downloads data from url, and makes changes to match the CSV format.\n",
    "\n",
    "  The CSVs may use spaces after the comma delimters (non-standard) or include\n",
    "  rows which do not represent well-formed examples. This function strips out\n",
    "  some of these problems.\n",
    "\n",
    "  Args:\n",
    "    filename: filename to save url to\n",
    "    url: URL of resource to download\n",
    "  \"\"\"\n",
    "  temp_file, _ = urllib.request.urlretrieve(url)\n",
    "  with tf.io.gfile.GFile(temp_file, 'r') as temp_file_object:\n",
    "    with tf.io.gfile.GFile(filename, 'w') as file_object:\n",
    "      for line in temp_file_object:\n",
    "        line = line.strip()\n",
    "        line = line.replace(', ', ',')\n",
    "        if not line or ',' not in line:\n",
    "          continue\n",
    "        if line[-1] == '.':\n",
    "          line = line[:-1]\n",
    "        line += '\\n'\n",
    "        file_object.write(line)\n",
    "  tf.io.gfile.remove(temp_file)\n",
    "\n",
    "\n",
    "def download(data_dir):\n",
    "  \"\"\"Downloads census data if it is not already present.\n",
    "\n",
    "  Args:\n",
    "    data_dir: directory where we will access/save the census data\n",
    "  \"\"\"\n",
    "  tf.io.gfile.makedirs(data_dir)\n",
    "\n",
    "  training_file_path = os.path.join(data_dir, TRAINING_FILE)\n",
    "  if not tf.io.gfile.exists(training_file_path):\n",
    "    _download_and_clean_file(training_file_path, TRAINING_URL)\n",
    "\n",
    "  eval_file_path = os.path.join(data_dir, EVAL_FILE)\n",
    "  if not tf.io.gfile.exists(eval_file_path):\n",
    "    _download_and_clean_file(eval_file_path, EVAL_URL)\n",
    "\n",
    "  return training_file_path, eval_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5943a672-bec5-45a8-ac88-50205c5d1ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_path, eval_file_path = download(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36459527-4942-481b-bb0d-c79108bbbfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /tmp/census_data/adult.data.csv data/adult.data.csv\n",
    "!cp /tmp/census_data/adult.test.csv data/adult.test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6b82e4e-7afa-4828-ad94-1ffbe3615005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/census_data/adult.data.csv\n",
      "/tmp/census_data/adult.test.csv\n"
     ]
    }
   ],
   "source": [
    "print(training_file_path)\n",
    "print(eval_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c820b5e0-0572-4928-a1af-faa2eb76010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(training_file_path, names=_CSV_COLUMNS, na_values='?')\n",
    "eval_df = pd.read_csv(eval_file_path, names=_CSV_COLUMNS, na_values='?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c42ab34-374d-4aa2-99a7-41f23bcc00f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race  gender  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country income_bracket  \n",
       "0          2174             0              40  United-States          <=50K  \n",
       "1             0             0              13  United-States          <=50K  \n",
       "2             0             0              40  United-States          <=50K  \n",
       "3             0             0              40  United-States          <=50K  \n",
       "4             0             0              40           Cuba          <=50K  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2813ea4-ceb4-4052-8898-17c685279b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNUSED_COLUMNS = ['fnlwgt', 'education', 'gender']\n",
    "\n",
    "\n",
    "def preprocess(dataframe):\n",
    "  \"\"\"Converts categorical features to numeric. Removes unused columns.\n",
    "\n",
    "  Args:\n",
    "    dataframe: Pandas dataframe with raw data\n",
    "\n",
    "  Returns:\n",
    "    Dataframe with preprocessed data\n",
    "  \"\"\"\n",
    "  dataframe = dataframe.drop(columns=UNUSED_COLUMNS)\n",
    "\n",
    "  # Convert integer valued (numeric) columns to floating point\n",
    "  numeric_columns = dataframe.select_dtypes(['int64']).columns\n",
    "  dataframe[numeric_columns] = dataframe[numeric_columns].astype('float32')\n",
    "\n",
    "  # Convert categorical columns to numeric\n",
    "  cat_columns = dataframe.select_dtypes(['object']).columns\n",
    "  dataframe[cat_columns] = dataframe[cat_columns].apply(lambda x: x.astype(_CATEGORICAL_TYPES[x.name]))\n",
    "  dataframe[cat_columns] = dataframe[cat_columns].apply(lambda x: x.cat.codes)\n",
    "  return dataframe\n",
    "\n",
    "prepped_train_df = preprocess(train_df)\n",
    "prepped_eval_df = preprocess(eval_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "571e2bda-4a55-4362-a367-4779e80e2d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.0</td>\n",
       "      <td>6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  workclass  education_num  marital_status  occupation  relationship  \\\n",
       "0  39.0          6           13.0               4           0             1   \n",
       "1  50.0          5           13.0               2           3             0   \n",
       "2  38.0          3            9.0               0           5             1   \n",
       "3  53.0          3            7.0               2           5             0   \n",
       "4  28.0          3           13.0               2           9             5   \n",
       "\n",
       "   race  capital_gain  capital_loss  hours_per_week  native_country  \\\n",
       "0     4        2174.0           0.0            40.0              38   \n",
       "1     4           0.0           0.0            13.0              38   \n",
       "2     4           0.0           0.0            40.0              38   \n",
       "3     2           0.0           0.0            40.0              38   \n",
       "4     2           0.0           0.0            40.0               4   \n",
       "\n",
       "   income_bracket  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepped_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc8f6433-c8ad-42ca-aab6-16a66c9e89bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test data with labels.\n",
    "# The pop() method will extract (copy) and remove the label column from the dataframe\n",
    "train_x, train_y = prepped_train_df, prepped_train_df.pop(_LABEL_COLUMN)\n",
    "eval_x, eval_y = prepped_eval_df, prepped_eval_df.pop(_LABEL_COLUMN)\n",
    "\n",
    "# Reshape label columns for use with tf.data.Dataset\n",
    "train_y = np.asarray(train_y).astype('float32').reshape((-1, 1))\n",
    "eval_y = np.asarray(eval_y).astype('float32').reshape((-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e57021a1-cb3c-4223-af63-992c29ca9ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(dataframe):\n",
    "  \"\"\"Scales numerical columns using their means and standard deviation to get\n",
    "  z-scores: the mean of each numerical column becomes 0, and the standard\n",
    "  deviation becomes 1. This can help the model converge during training.\n",
    "\n",
    "  Args:\n",
    "    dataframe: Pandas dataframe\n",
    "\n",
    "  Returns:\n",
    "    Input dataframe with the numerical columns scaled to z-scores\n",
    "  \"\"\"\n",
    "  dtypes = list(zip(dataframe.dtypes.index, map(str, dataframe.dtypes)))\n",
    "  # Normalize numeric columns.\n",
    "  for column, dtype in dtypes:\n",
    "      if dtype == 'float32':\n",
    "          dataframe[column] -= dataframe[column].mean()\n",
    "          dataframe[column] /= dataframe[column].std()\n",
    "  return dataframe\n",
    "\n",
    "\n",
    "# Join train_x and eval_x to normalize on overall means and standard\n",
    "# deviations. Then separate them again.\n",
    "all_x = pd.concat([train_x, eval_x], keys=['train', 'eval'])\n",
    "all_x = standardize(all_x)\n",
    "train_x, eval_x = all_x.xs('train'), all_x.xs('eval')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0168e0a6-4122-4aa2-a4d1-e3a13e882092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, shuffle, num_epochs, batch_size):\n",
    "  \"\"\"Generates an input function to be used for model training.\n",
    "\n",
    "  Args:\n",
    "    features: numpy array of features used for training or inference\n",
    "    labels: numpy array of labels for each example\n",
    "    shuffle: boolean for whether to shuffle the data or not (set True for\n",
    "      training, False for evaluation)\n",
    "    num_epochs: number of epochs to provide the data for\n",
    "    batch_size: batch size for training\n",
    "\n",
    "  Returns:\n",
    "    A tf.data.Dataset that can provide data to the Keras model for training or\n",
    "      evaluation\n",
    "  \"\"\"\n",
    "  if labels is None:\n",
    "    inputs = features\n",
    "  else:\n",
    "    inputs = (features, labels)\n",
    "  dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "\n",
    "  if shuffle:\n",
    "    dataset = dataset.shuffle(buffer_size=len(features))\n",
    "\n",
    "  # We call repeat after shuffling, rather than before, to prevent separate\n",
    "  # epochs from blending together.\n",
    "  dataset = dataset.repeat(num_epochs)\n",
    "  dataset = dataset.batch(batch_size)\n",
    "  return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdde22cf-3564-4f07-8bbd-93f4a1db6b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 10:00:27.834956: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-07 10:00:27.835047: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-07 10:00:27.835083: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (10b118e40db8): /proc/driver/nvidia/version does not exist\n",
      "2022-05-07 10:00:27.840960: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Pass a numpy array by using DataFrame.values\n",
    "training_dataset = input_fn(features=train_x.values,\n",
    "                    labels=train_y,\n",
    "                    shuffle=True,\n",
    "                    num_epochs=NUM_EPOCHS,\n",
    "                    batch_size=BATCH_SIZE)\n",
    "\n",
    "num_eval_examples = eval_x.shape[0]\n",
    "\n",
    "# Pass a numpy array by using DataFrame.values\n",
    "validation_dataset = input_fn(features=eval_x.values,\n",
    "                    labels=eval_y,\n",
    "                    shuffle=False,\n",
    "                    num_epochs=NUM_EPOCHS,\n",
    "                    batch_size=num_eval_examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "288a8d21-9c89-4b47-917f-f14c97e47ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model(input_dim, learning_rate):\n",
    "  \"\"\"Creates Keras Model for Binary Classification.\n",
    "\n",
    "  Args:\n",
    "    input_dim: How many features the input has\n",
    "    learning_rate: Learning rate for training\n",
    "\n",
    "  Returns:\n",
    "    The compiled Keras model (still needs to be trained)\n",
    "  \"\"\"\n",
    "  Dense = tf.keras.layers.Dense\n",
    "  model = tf.keras.Sequential(\n",
    "    [\n",
    "        Dense(100, activation=tf.nn.relu, kernel_initializer='uniform', input_shape=(input_dim,)),\n",
    "        Dense(75, activation=tf.nn.relu),\n",
    "        Dense(50, activation=tf.nn.relu),\n",
    "        Dense(25, activation=tf.nn.relu),\n",
    "        Dense(1, activation=tf.nn.sigmoid)\n",
    "    ])\n",
    "\n",
    "  # Custom Optimizer:\n",
    "  # https://www.tensorflow.org/api_docs/python/tf/train/RMSPropOptimizer\n",
    "  optimizer = tf.keras.optimizers.RMSprop(lr=learning_rate)\n",
    "\n",
    "  # Compile Keras model\n",
    "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9036451e-2a54-4088-9b13-f62c2091f135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 11\n",
      "Number of examples: 32561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_train_examples, input_dim = train_x.shape\n",
    "print('Number of features: {}'.format(input_dim))\n",
    "print('Number of examples: {}'.format(num_train_examples))\n",
    "\n",
    "keras_model = create_keras_model(input_dim=input_dim, learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae1250c0-3f3d-497f-b91d-5b8f8add9f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               1200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 75)                7575      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                3800      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 13,876\n",
      "Trainable params: 13,876\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab642086-7f91-4362-9f75-4eecf02cd3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Learning Rate decay.\n",
    "lr_decay_cb = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: LEARNING_RATE + 0.02 * (0.5 ** (1 + epoch)),\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab6dc549-cdd4-4676-ae74-6d96a7ea8253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 10:02:20.801160: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 1s 3ms/step - loss: 0.5875 - accuracy: 0.7865 - val_loss: 0.3878 - val_accuracy: 0.8085\n",
      "Epoch 2/20\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.015.\n",
      "254/254 [==============================] - 1s 3ms/step - loss: 0.3603 - accuracy: 0.8339 - val_loss: 0.3703 - val_accuracy: 0.8308\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0125.\n",
      "254/254 [==============================] - 1s 3ms/step - loss: 0.3418 - accuracy: 0.8414 - val_loss: 0.3361 - val_accuracy: 0.8462\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.01125.\n",
      "254/254 [==============================] - 1s 3ms/step - loss: 0.3349 - accuracy: 0.8451 - val_loss: 0.3383 - val_accuracy: 0.8484\n",
      "Epoch 5/20\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.010625.\n",
      "254/254 [==============================] - 1s 3ms/step - loss: 0.3327 - accuracy: 0.8469 - val_loss: 0.3264 - val_accuracy: 0.8517\n",
      "Epoch 6/20\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0103125.\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3308 - accuracy: 0.8486 - val_loss: 0.3255 - val_accuracy: 0.8480\n",
      "Epoch 7/20\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.01015625.\n",
      "254/254 [==============================] - 1s 3ms/step - loss: 0.3280 - accuracy: 0.8480 - val_loss: 0.3217 - val_accuracy: 0.8519\n",
      "Epoch 8/20\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.010078125.\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3269 - accuracy: 0.8485 - val_loss: 0.3261 - val_accuracy: 0.8522\n",
      "Epoch 9/20\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0100390625.\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3249 - accuracy: 0.8492 - val_loss: 0.3221 - val_accuracy: 0.8520\n",
      "Epoch 10/20\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.01001953125.\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3253 - accuracy: 0.8500 - val_loss: 0.3199 - val_accuracy: 0.8511\n",
      "Epoch 11/20\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.010009765625.\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3243 - accuracy: 0.8488 - val_loss: 0.3233 - val_accuracy: 0.8470\n",
      "Epoch 12/20\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.010004882812500001.\n",
      "254/254 [==============================] - 1s 3ms/step - loss: 0.3236 - accuracy: 0.8485 - val_loss: 0.3293 - val_accuracy: 0.8514\n",
      "Epoch 13/20\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.01000244140625.\n",
      "254/254 [==============================] - 1s 3ms/step - loss: 0.3243 - accuracy: 0.8505 - val_loss: 0.3251 - val_accuracy: 0.8468\n",
      "Epoch 14/20\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.010001220703125.\n",
      "254/254 [==============================] - 1s 3ms/step - loss: 0.3231 - accuracy: 0.8488 - val_loss: 0.3282 - val_accuracy: 0.8515\n",
      "Epoch 15/20\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0100006103515625.\n",
      "254/254 [==============================] - 1s 3ms/step - loss: 0.3241 - accuracy: 0.8518 - val_loss: 0.3217 - val_accuracy: 0.8511\n",
      "Epoch 16/20\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.01000030517578125.\n",
      "254/254 [==============================] - 1s 3ms/step - loss: 0.3222 - accuracy: 0.8505 - val_loss: 0.3304 - val_accuracy: 0.8481\n",
      "Epoch 17/20\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.010000152587890625.\n",
      "254/254 [==============================] - 1s 3ms/step - loss: 0.3236 - accuracy: 0.8490 - val_loss: 0.3321 - val_accuracy: 0.8420\n",
      "Epoch 18/20\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.010000076293945313.\n",
      "254/254 [==============================] - 1s 3ms/step - loss: 0.3244 - accuracy: 0.8493 - val_loss: 0.3219 - val_accuracy: 0.8523\n",
      "Epoch 19/20\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.010000038146972657.\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3220 - accuracy: 0.8509 - val_loss: 0.3221 - val_accuracy: 0.8532\n",
      "Epoch 20/20\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.010000019073486329.\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.3235 - accuracy: 0.8503 - val_loss: 0.3366 - val_accuracy: 0.8425\n"
     ]
    }
   ],
   "source": [
    "history = keras_model.fit(training_dataset,\n",
    "                          epochs=NUM_EPOCHS,\n",
    "                          steps_per_epoch=int(num_train_examples/BATCH_SIZE),\n",
    "                          validation_data=validation_dataset,\n",
    "                          validation_steps=1,\n",
    "                          callbacks=[lr_decay_cb],\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4dc7905f-1c61-494e-92d7-e460b590c0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/keras_export/assets\n",
      "Model exported to:  None\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(keras_model, 'saved_model/keras_export')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98def78c-0315-4937-8522-d5f7501aa7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
